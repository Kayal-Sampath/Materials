{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"V6CWu0GzZNDI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643042040919,"user_tz":-330,"elapsed":962,"user":{"displayName":"leni satish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshCl1DsUfB9j1fhMZ68WDjZjN0qe01u2GN4QJeQ=s64","userId":"04185857616332793118"}},"outputId":"46d756ea-5acd-4bab-b81a-e2cf9facc093"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mydrive/MyDrive/SSN FDP/Day6/Data\n"]}],"source":["!pwd"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/mydrive')"],"metadata":{"id":"Q-KOgTQapWDx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643042051602,"user_tz":-330,"elapsed":6375,"user":{"displayName":"leni satish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshCl1DsUfB9j1fhMZ68WDjZjN0qe01u2GN4QJeQ=s64","userId":"04185857616332793118"}},"outputId":"94d76b5b-3b2b-4794-c452-52f4a0000e76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/mydrive; to attempt to forcibly remount, call drive.mount(\"/content/mydrive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bWZ8o8-Zm3a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643042055372,"user_tz":-330,"elapsed":5,"user":{"displayName":"leni satish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshCl1DsUfB9j1fhMZ68WDjZjN0qe01u2GN4QJeQ=s64","userId":"04185857616332793118"}},"outputId":"63c87245-ba16-43b6-c399-0bf399fbb95f"},"outputs":[{"output_type":"stream","name":"stdout","text":["cnn_histopath_model_save_demo.h5  histopathology.ipynb\tmini_trainset\n","cnn_histopath_weights_demo.hdf5   mini_testset_histo\n"]}],"source":["from google.colab import drive\n","import os\n","#drive.mount('/content/mydrive')\n","os.chdir(os.path.join('/','content','mydrive', 'MyDrive','SSN FDP', 'Day6', 'Data'))\n","!ls\n","#/content/mydrive/MyDrive/SSN FDP/Day6/Data"]},{"cell_type":"markdown","source":["# New section"],"metadata":{"id":"SgFcUbhfYsXf"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3407,"status":"ok","timestamp":1643042064281,"user":{"displayName":"leni satish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshCl1DsUfB9j1fhMZ68WDjZjN0qe01u2GN4QJeQ=s64","userId":"04185857616332793118"},"user_tz":-330},"id":"awroqJerZgIi","outputId":"78d23ce1-07e7-4600-fdef-04e7d152925b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: visualkeras in /usr/local/lib/python3.7/dist-packages (0.0.2)\n","Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (1.19.5)\n","Requirement already satisfied: aggdraw>=1.3.11 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (1.3.12)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (7.1.2)\n"]}],"source":["# Part 1 - Building the CNN\n","\n","# Importing the Keras libraries and packages\n","!pip install visualkeras\n","import visualkeras\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization\n","#from keras.layers.normalization import BatchNormalization\n","from keras.layers import SeparableConv2D, MaxPooling2D\n","from keras.layers import Activation, Flatten, Dropout, Dense\n","from keras import backend as K\n","\n","\n","import matplotlib\n","matplotlib.use('TkAgg')\n","import matplotlib.pyplot as plt\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.optimizers import Adagrad, Adadelta, Nadam\n","#from keras.optimizers import Adagrad Adadelta, Nadam\n","from keras.utils import np_utils\n","from sklearn.metrics import classification_report, confusion_matrix\n","from imutils import paths\n","import numpy as np\n","import os\n","\n","num_cores=12\n","size_batch=4#16\n","use_multi_proc =False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7F1Cxta1T-p"},"outputs":[],"source":["def get_model(width, height, depth, classes):\n","  model = Sequential()    # initialize model\n","  inputShape = (height, width, depth)\n","  channelDim = -1\n","                                      \n","  if K.image_data_format() == 'channels_first':\n","      inputShape = (depth, height, width)\n","      channelDim = 1 \n","\n","  model.add(SeparableConv2D(32, (3,3), padding='same', input_shape=inputShape))\n","  model.add(Activation('relu'))\n","  model.add(BatchNormalization(axis=channelDim))\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","\n","  model.add(SeparableConv2D(64, (3,3), padding='same'))\n","  model.add(Activation('relu'))\n","  model.add(BatchNormalization(axis=channelDim))\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","  model.add(SeparableConv2D(64, (3,3), padding='same'))\n","  model.add(Activation('relu'))\n","  model.add(BatchNormalization(axis=channelDim))\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","  #model.add(Dropout(0.25))\n","\n","  # CONV2D(128) -> RELU -> BATCH NORM -> CONV2D(128) -> RELU -> BATCH NORM -> CONV2D(128) -> RELU -> BATCH NORM\n","  # -> POOL2D -> DROPOUT\n","  model.add(SeparableConv2D(128,(3,3), padding='same'))\n","  model.add(Activation('relu'))\n","  model.add(BatchNormalization(axis=channelDim))\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","\n"," \n","\n","  # FC(256) -> RELU -> BATCH NORM -> DROPOUT\n","  model.add(Flatten())\n","  model.add(Dense(256))\n","  model.add(Activation('relu'))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","\n","    # Softmax clqssifier\n","  model.add(Dense(classes))\n","  model.add(Activation('softmax'))\n","  visualkeras.layered_view(model).show()\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45872,"status":"ok","timestamp":1643042127556,"user":{"displayName":"leni satish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshCl1DsUfB9j1fhMZ68WDjZjN0qe01u2GN4QJeQ=s64","userId":"04185857616332793118"},"user_tz":-330},"id":"QanML5Hp2aiS","outputId":"9650bd17-7bd4-47eb-cd66-a8db903277f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 733 images belonging to 3 classes.\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," separable_conv2d_8 (Separab  (None, 128, 128, 32)     155       \n"," leConv2D)                                                       \n","                                                                 \n"," activation_12 (Activation)  (None, 128, 128, 32)      0         \n","                                                                 \n"," batch_normalization_10 (Bat  (None, 128, 128, 32)     128       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_8 (MaxPooling  (None, 64, 64, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," separable_conv2d_9 (Separab  (None, 64, 64, 64)       2400      \n"," leConv2D)                                                       \n","                                                                 \n"," activation_13 (Activation)  (None, 64, 64, 64)        0         \n","                                                                 \n"," batch_normalization_11 (Bat  (None, 64, 64, 64)       256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_9 (MaxPooling  (None, 32, 32, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," separable_conv2d_10 (Separa  (None, 32, 32, 64)       4736      \n"," bleConv2D)                                                      \n","                                                                 \n"," activation_14 (Activation)  (None, 32, 32, 64)        0         \n","                                                                 \n"," batch_normalization_12 (Bat  (None, 32, 32, 64)       256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_10 (MaxPoolin  (None, 16, 16, 64)       0         \n"," g2D)                                                            \n","                                                                 \n"," separable_conv2d_11 (Separa  (None, 16, 16, 128)      8896      \n"," bleConv2D)                                                      \n","                                                                 \n"," activation_15 (Activation)  (None, 16, 16, 128)       0         \n","                                                                 \n"," batch_normalization_13 (Bat  (None, 16, 16, 128)      512       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_11 (MaxPoolin  (None, 8, 8, 128)        0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_2 (Flatten)         (None, 8192)              0         \n","                                                                 \n"," dense_4 (Dense)             (None, 256)               2097408   \n","                                                                 \n"," activation_16 (Activation)  (None, 256)               0         \n","                                                                 \n"," batch_normalization_14 (Bat  (None, 256)              1024      \n"," chNormalization)                                                \n","                                                                 \n"," dropout_2 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 3)                 771       \n","                                                                 \n"," activation_17 (Activation)  (None, 3)                 0         \n","                                                                 \n","=================================================================\n","Total params: 2,116,542\n","Trainable params: 2,115,454\n","Non-trainable params: 1,088\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/nadam.py:73: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Nadam, self).__init__(name, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","23/52 [============>.................] - ETA: 33s - loss: 0.6112 - accuracy: 0.8035WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1040 batches). You may need to use the repeat() function when building your dataset.\n","52/52 [==============================] - 30s 505ms/step - loss: 0.6112 - accuracy: 0.8035\n","Training complete\n"]}],"source":["number_of_train = 1670\n","number_of_test = 300\n","numEpochs = 20\n","batchSize = 32\n","lrRate = 1e-2\n","lrRateDecay = lrRate/numEpochs\n","\n","train_data_dir = 'mini_trainset/'\n","test_data_dir = 'mini_testset_histo/'\n","\n","            \n","train_list = list(paths.list_images(train_data_dir))\n","test_list = list(paths.list_images(test_data_dir))\n","  #Initializing training data augmentation object\n","trainAug = ImageDataGenerator(rotation_range=20,\n","                            rescale=1/255.0,\n","                            zoom_range=0.05,\n","                            height_shift_range=0.1,\n","                            width_shift_range=0.1,\n","                            horizontal_flip=True,\n","                            vertical_flip=True,\n","                            shear_range=0.5,\n","                            fill_mode='nearest')\n","testAug = ImageDataGenerator(rescale=1/255.0)\n","#Initializing training and testing generator\n","trainGen = trainAug.flow_from_directory(train_data_dir,\n","                                        class_mode='categorical',\n","                                        target_size=(128,128), \n","                                        shuffle=True,                                                                                           \n","                                        batch_size=batchSize,\n","                                        color_mode='rgb')\n","\n","#model building\n","model = get_model(width=128, height=128, depth=3, classes=3)\n","model.summary()\n","opt = Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n","\n","#model compilation\n","model.compile(loss='categorical_crossentropy',\n","            optimizer=opt,\n","            metrics=['accuracy'])\n","\n","#to store the model after every epoch\n","#callbacks = [ModelCheckpoint(filepath='histopath_weights.{epoch:02d}-{val_loss:.2f}.h5')]   \n","\n","\n","#fit the model\n","history = model.fit_generator(trainGen,\n","                            steps_per_epoch=number_of_train // batchSize,\n","                            epochs=numEpochs)\n","\n","model.save('cnn_histopath_model_save_demo.h5')\n","model.save_weights('cnn_histopath_weights_demo.hdf5')\n","print('Training complete')"]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"a8-Bp_N--bh4"}},{"cell_type":"code","source":["testGen = testAug.flow_from_directory(test_data_dir,\n","                                    class_mode='categorical',\n","                                    target_size=(128,128),\n","                                    shuffle=False,\n","                                    batch_size=batchSize,\n","                                    color_mode='rgb')\n","\n","print(len(testGen.classes))\n","print(testGen.class_indices.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GVjN_eBPnYdm","executionInfo":{"status":"ok","timestamp":1643042127557,"user_tz":-330,"elapsed":14,"user":{"displayName":"leni satish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshCl1DsUfB9j1fhMZ68WDjZjN0qe01u2GN4QJeQ=s64","userId":"04185857616332793118"}},"outputId":"b14942b6-b9d4-4157-c14a-92a43dd902e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 300 images belonging to 3 classes.\n","300\n","dict_keys(['lung_aca', 'lung_n', 'lung_scc'])\n"]}]},{"cell_type":"code","source":["number_of_train = 1670\n","number_of_test = 300\n","numEpochs = 20\n","batchSize = 32\n","lrRate = 1e-2\n","lrRateDecay = lrRate/numEpochs\n","\n","train_data_dir = 'mini_trainset/'\n","test_data_dir = 'mini_testset_histo/'\n","\n","            \n","train_list = list(paths.list_images(train_data_dir))\n","test_list = list(paths.list_images(test_data_dir))\n","  #Initializing training data augmentation object\n","trainAug = ImageDataGenerator(rotation_range=20,\n","                            rescale=1/255.0,\n","                            zoom_range=0.05,\n","                            height_shift_range=0.1,\n","                            width_shift_range=0.1,\n","                            horizontal_flip=True,\n","                            vertical_flip=True,\n","                            shear_range=0.5,\n","                            fill_mode='nearest')\n","testAug = ImageDataGenerator(rescale=1/255.0)\n","#Initializing training and testing generator\n","trainGen = trainAug.flow_from_directory(train_data_dir,\n","                                        class_mode='categorical',\n","                                        target_size=(128,128), \n","                                        shuffle=True,                                                                                           \n","                                        batch_size=batchSize,\n","                                        color_mode='rgb')\n","\n","#model building\n","model = get_model(width=128, height=128, depth=3, classes=3)\n","model.summary()\n","opt = Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n","\n","#model compilation\n","model.compile(loss='categorical_crossentropy',\n","            optimizer=opt,\n","            metrics=['accuracy'])\n","\n","#to store the model after every epoch\n","#callbacks = [ModelCheckpoint(filepath='histopath_weights.{epoch:02d}-{val_loss:.2f}.h5')]   \n","\n","\n","#fit the model\n","history = model.fit_generator(trainGen,\n","                            steps_per_epoch=number_of_train // batchSize,\n","                            epochs=numEpochs)\n","\n","model.save('cnn_histopath_model_save_demo.h5')\n","model.save_weights('cnn_histopath_weights_demo.hdf5')\n","print('Training complete')"],"metadata":{"id":"5h50nxhBsyRR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643042179702,"user_tz":-330,"elapsed":46508,"user":{"displayName":"leni satish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshCl1DsUfB9j1fhMZ68WDjZjN0qe01u2GN4QJeQ=s64","userId":"04185857616332793118"}},"outputId":"d287ae8f-ff8c-4b9e-92ba-63b872e3bce6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 733 images belonging to 3 classes.\n","Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," separable_conv2d_12 (Separa  (None, 128, 128, 32)     155       \n"," bleConv2D)                                                      \n","                                                                 \n"," activation_18 (Activation)  (None, 128, 128, 32)      0         \n","                                                                 \n"," batch_normalization_15 (Bat  (None, 128, 128, 32)     128       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_12 (MaxPoolin  (None, 64, 64, 32)       0         \n"," g2D)                                                            \n","                                                                 \n"," separable_conv2d_13 (Separa  (None, 64, 64, 64)       2400      \n"," bleConv2D)                                                      \n","                                                                 \n"," activation_19 (Activation)  (None, 64, 64, 64)        0         \n","                                                                 \n"," batch_normalization_16 (Bat  (None, 64, 64, 64)       256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_13 (MaxPoolin  (None, 32, 32, 64)       0         \n"," g2D)                                                            \n","                                                                 \n"," separable_conv2d_14 (Separa  (None, 32, 32, 64)       4736      \n"," bleConv2D)                                                      \n","                                                                 \n"," activation_20 (Activation)  (None, 32, 32, 64)        0         \n","                                                                 \n"," batch_normalization_17 (Bat  (None, 32, 32, 64)       256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_14 (MaxPoolin  (None, 16, 16, 64)       0         \n"," g2D)                                                            \n","                                                                 \n"," separable_conv2d_15 (Separa  (None, 16, 16, 128)      8896      \n"," bleConv2D)                                                      \n","                                                                 \n"," activation_21 (Activation)  (None, 16, 16, 128)       0         \n","                                                                 \n"," batch_normalization_18 (Bat  (None, 16, 16, 128)      512       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_15 (MaxPoolin  (None, 8, 8, 128)        0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_3 (Flatten)         (None, 8192)              0         \n","                                                                 \n"," dense_6 (Dense)             (None, 256)               2097408   \n","                                                                 \n"," activation_22 (Activation)  (None, 256)               0         \n","                                                                 \n"," batch_normalization_19 (Bat  (None, 256)              1024      \n"," chNormalization)                                                \n","                                                                 \n"," dropout_3 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 3)                 771       \n","                                                                 \n"," activation_23 (Activation)  (None, 3)                 0         \n","                                                                 \n","=================================================================\n","Total params: 2,116,542\n","Trainable params: 2,115,454\n","Non-trainable params: 1,088\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/nadam.py:73: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Nadam, self).__init__(name, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","23/52 [============>.................] - ETA: 33s - loss: 0.6227 - accuracy: 0.7776WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1040 batches). You may need to use the repeat() function when building your dataset.\n","52/52 [==============================] - 30s 505ms/step - loss: 0.6227 - accuracy: 0.7776\n","Training complete\n"]}]},{"cell_type":"code","source":["# make prediction on test data\n","predIdx = model.predict(testGen)\n","predIdx = np.argmax(predIdx, axis=1)\n","\n","print(classification_report(testGen.classes,\n","                            predIdx,\n","                            target_names=testGen.class_indices.keys()))\n","confusionMatrix = confusion_matrix(testGen.classes, predIdx)\n","total = sum(sum(confusionMatrix))"],"metadata":{"id":"WWe2wgbVjSLV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643042197070,"user_tz":-330,"elapsed":5119,"user":{"displayName":"leni satish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshCl1DsUfB9j1fhMZ68WDjZjN0qe01u2GN4QJeQ=s64","userId":"04185857616332793118"}},"outputId":"1ed8be44-9bdc-4bd6-c6ba-a243e3f41100"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","    lung_aca       0.00      0.00      0.00       100\n","      lung_n       0.00      0.00      0.00       100\n","    lung_scc       0.33      1.00      0.50       100\n","\n","    accuracy                           0.33       300\n","   macro avg       0.11      0.33      0.17       300\n","weighted avg       0.11      0.33      0.17       300\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["    # compute accuracy, sensitivty, specificity\n","    # sensitivity measures the proportion of true positives also predicted as positives\n","    # Similarly, specificity measures the proportion of true negatives\n","accuracy = (confusionMatrix[0,0] + confusionMatrix[1,1]) / total\n","sensitivity = confusionMatrix[0,0] / (confusionMatrix[0,0] + confusionMatrix[0,1])\n","specificity = confusionMatrix[1,1] / (confusionMatrix[1,0] + confusionMatrix[1,1])\n","print(confusionMatrix)\n","print('accuracy: {:4f}'.format(accuracy))\n","print('sensitivity: {:4f}'.format(sensitivity))\n","print('specificity: {:4f}'.format(specificity))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96lLbCUdjR8c","executionInfo":{"status":"ok","timestamp":1643042611261,"user_tz":-330,"elapsed":363,"user":{"displayName":"leni satish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshCl1DsUfB9j1fhMZ68WDjZjN0qe01u2GN4QJeQ=s64","userId":"04185857616332793118"}},"outputId":"193071f7-63a9-40bd-c952-27bf9c6b789b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[  0   0 100]\n"," [  0   0 100]\n"," [  0   0 100]]\n","accuracy: 0.000000\n","sensitivity:  nan\n","specificity:  nan\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in long_scalars\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in long_scalars\n","  \n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"histopathology.ipynb","provenance":[{"file_id":"1G1uNikzz99SzYA-ZTVkX08Zsitzr48wP","timestamp":1642141017098}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}